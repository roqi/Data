{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = requests.Session()\n",
    "HOMEPAGE_URL = 'https://www.linkedin.com/uas/login'\n",
    "#LOGIN_URL = 'https://www.linkedin.com/feed'\n",
    "html = client.get(HOMEPAGE_URL).content\n",
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "csrf = soup.find('input', type=\"hidden\")['value']\n",
    "\n",
    "##specify 'cookie' and 'user-agent'\n",
    "##change the cookie info as shown in your 'inspect' info. Replace value in 'JSESSIONID' with csrf::: '...JSESSIONID={}...'.format(csrf)\n",
    "headers = {'cookie': 'XXX; \\\n",
    "JSESSIONID={}; XXX'.format(csrf),\n",
    "        'user-agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Mobile Safari/537.36'}\n",
    "\n",
    "\n",
    "url= 'https://www.linkedin.com/search/results/index/?keywords={}&origin=HISTORY'.format('3M Drug Delivery Systems')\n",
    "response = client.get(url=url, headers=headers)\n",
    "parse_response = BeautifulSoup(response.content,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = parse_response.find_all('code', style =\"display: none\")\n",
    "for i in range(len(x)):\n",
    "    if 'Silvia' in x[i].get_text():\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_response.find_all('code', style =\"display: none\")[i].string\n",
    "data=json.loads(data)\n",
    "data = data['included']\n",
    "\n",
    "pplist = []\n",
    "for i in data:\n",
    "    if i['$type'] == 'com.linkedin.voyager.identity.shared.MiniProfile':\n",
    "        pplist.append(i)\n",
    "        \n",
    "pplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##requests\n",
    "\n",
    "##write in function:\n",
    "\n",
    "def LinkedIn_scraper_company(company):\n",
    "    client = requests.Session()\n",
    "    HOMEPAGE_URL = 'https://www.linkedin.com/uas/login'\n",
    "    #LOGIN_URL = 'https://www.linkedin.com/feed'\n",
    "    html = client.get(HOMEPAGE_URL).content\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    csrf = soup.find('input', type=\"hidden\")['value']\n",
    "\n",
    "\n",
    "##change the cookie info as yours; replace'JSESSIONID' value in 'cookie with csrf\n",
    "    headers = {'cookie':'XXXX\\\n",
    "JSESSIONID={}; XXXX'.format(csrf),\n",
    "        'user-agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Mobile Safari/537.36'}\n",
    "#login_information = {\n",
    "    #'session_key':'#####',\n",
    "    #'session_password':'####',\n",
    "    #'loginCsrfParam': csrf,\n",
    "#}\n",
    "\n",
    "    url= 'https://www.linkedin.com/search/results/index/?keywords={}&origin=HISTORY'.format(company)\n",
    "    response = client.get(url=url, headers=headers)\n",
    "    parse_response = BeautifulSoup(response.content,\"lxml\")\n",
    "    x = parse_response.find_all('code', style =\"display: none\")\n",
    "    data = parse_response.find_all('code', style =\"display: none\")[10].string\n",
    "    data=json.loads(data)\n",
    "    data = data['included']\n",
    "\n",
    "    pplist = []\n",
    "    for i in data:\n",
    "        if i['$type'] == 'com.linkedin.voyager.identity.shared.MiniProfile'\\\n",
    "        and company.strip()[0] in i['occupation']:\n",
    "            pplist.append(i)\n",
    "        \n",
    "    return(pplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinkedIn_scraper_company('Walmart CEO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list()\n",
    "result = LinkedIn_scraper_company('3M Drug Delivery Systems CEO')\n",
    "for t in result:\n",
    "    if 'CEO' or 'President' in t['occupation']:\n",
    "        name = t['firstName']+' '+t['lastName']\n",
    "        l.append(name)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = ['Walmart', '3M Drug Delivery Systems', 'Amazon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "n = len(company)\n",
    "i = 0\n",
    "list_name = []\n",
    "while i < n:\n",
    "    companyname = company[i]\n",
    "    try:\n",
    "        result = LinkedIn_scraper_company(companyname+ ' ' + 'CEO')\n",
    "        for t in result:\n",
    "            if 'CEO' or 'President' in t['occupation']:\n",
    "                name = t['firstName']+' '+t['lastName']\n",
    "                list_name.append(name)\n",
    "                i+=1\n",
    "                break\n",
    "        else:\n",
    "            list_name.append('NA')\n",
    "            i+=1\n",
    "                \n",
    "    except:\n",
    "        print(company[i])\n",
    "        print(\"Connection refused by the server..\")\n",
    "        print(\"Let me sleep for 30 seconds\")\n",
    "        print(\"ZZzzzz...\")\n",
    "        time.sleep(30)\n",
    "        print(\"Was a nice sleep, now let me continue...\")\n",
    "        continue\n",
    "                \n",
    "    \n",
    "\n",
    "print(list_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Selenium\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "query_keyword = ['Eneida Boniche Silcott', 'Ippocratis (Ippo) Vrohidis', 'Ethan Han']\n",
    "print ('Enter the linkedin email')\n",
    "email= input()\n",
    "print (\"Enter the LinkedIn password\")\n",
    "password= input()\n",
    "\n",
    "#Open Chrome web \n",
    "#driver = webdriver.Chrome()\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "\n",
    "#Login bu username/password\n",
    "email_box = driver.find_element_by_id('username')\n",
    "email_box.send_keys(email)\n",
    "pass_box = driver.find_element_by_id('password')\n",
    "pass_box.send_keys(password)\n",
    "submit_button = driver.find_element_by_class_name(\"login__form_action_container\")\n",
    "submit_button.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "#Find Name and return\n",
    "def getName(driver):\n",
    "        nameXpath = \"//h1[contains(@class, 'pv-top-card-section')]\"\n",
    "        time.sleep(10)\n",
    "        name = driver.find_element_by_xpath(nameXpath).text\n",
    "        return name\n",
    "\n",
    "def getLocation(driver):\n",
    "    nameXpath = \"//h3[contains(@class, 'pv-top-card-section')]\"\n",
    "    loc = driver.find_element_by_xpath(nameXpath).text\n",
    "    return loc\n",
    "\n",
    "def getEducation(driver):\n",
    "    nameXpath = \"//span[contains(@class, 'pv-top-card-v2-section__school')]\"\n",
    "    edu = driver.find_element_by_xpath(nameXpath).text\n",
    "    return edu\n",
    "\n",
    "def getConnections(driver):\n",
    "    nameXpath = \"//span[contains(@class, 'pv-top-card-v2-section__connections')]\"\n",
    "    conn = driver.find_element_by_xpath(nameXpath).text\n",
    "    return conn\n",
    "\n",
    "def saveAsCSV(data):\n",
    "    fileName = \"linkedin_result.csv\"\n",
    "    f = open(fileName, \"a\")\n",
    "    headers=\"Name,Location,Education,Connections\\n\"\n",
    "    f.write(data + '\\n')\n",
    "\n",
    "#For each profile name in query_keywords, retrive name, education, experience and number of connections\n",
    "for query in query_keyword:\n",
    "    try:\n",
    "        driver.get(\n",
    "            'https://www.linkedin.com/search/results/index/?keywords=' + query)\n",
    "\n",
    "        xpath = \"(//span[text()='\" + query + \"'])[1]\"\n",
    "        #print (xpath)\n",
    "        time.sleep(10)\n",
    "        driver.find_element_by_xpath(xpath).click()\n",
    "        data = ''\n",
    "        try :\n",
    "            name = getName(driver)\n",
    "            print (name)\n",
    "            data += name + ','\n",
    "        except Exception as ex:\n",
    "            data += 'NA,'\n",
    "\n",
    "        try:\n",
    "            loc = getLocation(driver)\n",
    "            print(loc)\n",
    "            data += loc + ','\n",
    "        except Exception as ex:\n",
    "            data += 'NA,'\n",
    "\n",
    "        try:\n",
    "            edu = getEducation(driver)\n",
    "            print(edu)\n",
    "            data += edu + ','\n",
    "        except Exception as ex:\n",
    "            data += 'NA,'\n",
    "\n",
    "        try:\n",
    "            conn = getConnections(driver)\n",
    "            print(conn)\n",
    "            data += conn + ','\n",
    "        except Exception as ex:\n",
    "            data += 'NA,'\n",
    "\n",
    "        print (data)\n",
    "        saveAsCSV(data)\n",
    "    except Exception as e:\n",
    "        print(\"Exception in retrieving data\" + e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
