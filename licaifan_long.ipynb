{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.微贷网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "url = 'https://www.weidai.com.cn/list/goodsList?type=0&periodType=0&sort=0&page=180&rows=10&goodsType=BIDDING'\n",
    "response = requests.get(url,headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.162 Mobile Safari/537.36'}\n",
    "url2 = \"https://www.weidai.com.cn/bid/newGoodsDetail?hash=&bid=&goodsNo=%s\" %sample['goodsNo']\n",
    "\n",
    "response2 = requests.get(url2,headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response2 = requests.get(url2,headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "results_page = BeautifulSoup(response2.content,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'资金周转'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(results_page.find('p').get_text())['data']['userRiskInfoVO']['borrowUse']\n",
    "##results_page.find('p').get_text().find('borrowUse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_page.find('ul', class_='tableDetailUL.clearfix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "##headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.162 Mobile Safari/537.36'}\n",
    "datelist = list()\n",
    "valuelist = list()\n",
    "ratelist = list()\n",
    "titlelist = list()\n",
    "maturlist = list()\n",
    "\n",
    "urllist = list()\n",
    "\n",
    "for i in range(180):\n",
    "    response = ''\n",
    "    url = 'https://www.weidai.com.cn/list/goodsList?type=0&periodType=0&sort=0&page=%d&rows=10&goodsType=BIDDING'%(i+1)\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(url,headers=headers).json()\n",
    "            length = len(response['data']['data'])\n",
    "            for j in range(length):\n",
    "                timestamp = response['data']['data'][j]['openTime']\n",
    "                Date = datetime.datetime.utcfromtimestamp(int(str(timestamp)[:-3])).strftime('%Y-%m-%d %H:%M:%S')[0:10]\n",
    "                Value = response['data']['data'][j]['goodsPrice']\n",
    "                Rate = response['data']['data'][j]['baseRate']\n",
    "                Title = response['data']['data'][j]['goodsTitle']\n",
    "                Maturity = response['data']['data'][j]['month']\n",
    "                goodsNo = response['data']['data'][j]['goodsNo']\n",
    "                url2 = \"https://www.weidai.com.cn/bid/newGoodsDetail?hash=&bid=&goodsNo=%s\" %goodsNo\n",
    "                datelist.append(Date)\n",
    "                valuelist.append(Value)\n",
    "                ratelist.append(Rate)\n",
    "                titlelist.append(Title)\n",
    "                maturlist.append(Maturity)\n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "                urllist.append(url2)\n",
    "                ##break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uselist = list()\n",
    "for u in urllist:\n",
    "    response2 = ''\n",
    "    while response2 == '':\n",
    "        try:\n",
    "            response2 = requests.get(u,headers=headers)\n",
    "            results_page = BeautifulSoup(response2.content,'lxml')\n",
    "            try:\n",
    "                borrowUse = json.loads(results_page.find('p').get_text())['data']['userRiskInfoVO']['borrowUse']\n",
    "            except:\n",
    "                borrowUse = \"null\"\n",
    "        \n",
    "        \n",
    "            uselist.append(borrowUse)\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist.append((datelist[i], valuelist[i], ratelist[i], titlelist[i], uselist[i], maturlist[i]))\n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "outfile = open(\"weidaiwang_____plus.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Date, Value(Yuan), Rate(%), Title, Use, Maturity(month)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.宜贷网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection refused by the server..\n",
      "Let me sleep for 5 seconds\n",
      "ZZzzzz...\n",
      "Was a nice sleep, now let me continue...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "\n",
    "urlydlist = list()\n",
    "    \n",
    "for i in range(1446,1500):\n",
    "    response = ''\n",
    "    url = \"https://www.yidai.com/invest/index.html?page=%s\"%(i+1)\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(url,headers=headers)\n",
    "            results_page = BeautifulSoup(response.content,'lxml')\n",
    "    \n",
    "            for tag in results_page.find_all('a', class_='f18'):\n",
    "                titlelist.append(tag.get('title'))\n",
    "        \n",
    "                urlydlist.append(tag.get('href'))\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "            for rate in results_page.find_all('li', class_=\"col-110 relative\"):\n",
    "                ratelist.append(rate.find('span', class_='f20 c-orange').get_text()[:-2])\n",
    "    \n",
    "            for value in results_page.find_all('li', class_=\"col-180\"):\n",
    "                valuelist.append(value.find('span', class_='f20 c-333').get_text())\n",
    "    \n",
    "            for matur in results_page.find_all('li', class_=\"col-120\"):\n",
    "                try:\n",
    "                    maturity = matur.find('span', class_='f20 c-333').get_text()\n",
    "                    maturlist.append(maturity)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            for date in results_page.find_all('span', class_=\"tender-time\"):\n",
    "                datelist.append(date.get_text()[5:])\n",
    "\n",
    "\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rate2list = list()\n",
    "for r in ratelist:\n",
    "    if len(r) > 10:\n",
    "        rate2 = r[:r.find('%')]\n",
    "    else:\n",
    "        rate2 = r\n",
    "\n",
    "    rate2list.append(rate2)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection refused by the server..\n",
      "Let me sleep for 5 seconds\n",
      "ZZzzzz...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ae7e516d0963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mresponse2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mresults_page2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    744\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    600\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m                 decoded = self._decode(chunk, decode_content=decode_content,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# amt > self.chunk_left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mreturned_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Toss the CRLF at the end of the chunk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ae7e516d0963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Let me sleep for 5 seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ZZzzzz...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Was a nice sleep, now let me continue...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "uselist=list()\n",
    "for j in urlydlist:\n",
    "    response2 = ''\n",
    "    while response2 == '':\n",
    "        try:\n",
    "            response2 = requests.get(j,headers=headers)\n",
    "            results_page2 = BeautifulSoup(response2.content,'lxml')\n",
    "            text = []\n",
    "            for e in results_page2.findAll('br'):\n",
    "                e.extract()\n",
    "            p = results_page2.find_all('div', class_='text')[1]\n",
    "\n",
    "            for x in p:\n",
    "                text.append(str(x))\n",
    "            if text[-7] == ' ':\n",
    "                useinfo = text[-8]\n",
    "            else:\n",
    "                useinfo = text[-7]\n",
    "            useinfo = re.sub('\\s+', '', useinfo)\n",
    "            uselist.append(useinfo)\n",
    "        except:\n",
    "            uselist.append('Check by url later')\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "response2 = requests.get(urlydlist[595],headers=headers)\n",
    "results_page2 = BeautifulSoup(response2.content,'lxml')\n",
    "text = []\n",
    "for e in results_page2.findAll('br'):\n",
    "    e.extract()\n",
    "p = results_page2.find_all('div', class_='text')[1]\n",
    "\n",
    "for x in p:\n",
    "    text.append(str(x))\n",
    "if text[-7] == ' ':\n",
    "    useinfo = text[-8]\n",
    "else:\n",
    "    useinfo = text[-7]\n",
    "useinfo = re.sub('\\s+', '', useinfo)\n",
    "uselist.append(useinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stoin(a):\n",
    "   # a = list(a)\n",
    "    a = [x for x in a if x != ',']\n",
    "\n",
    "    magic = lambda nums: int(''.join(str(i) for i in nums))\n",
    "    a = magic(a)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value2list=list()\n",
    "for v in valuelist:\n",
    "    value2list.append(stoin(v[:-3]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist.append((datelist[i], value2list[i], rate2list[i], titlelist[i], urlydlist[i], maturlist[i]))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "outfile = open(\"yidaiwangplus2.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Date, Value(Yuan), Rate(%), Title, url, Maturity(month)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(uselist)):\n",
    "    rawlist.append((uselist[i]))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "outfile = open(\"ydwusenew3.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"use\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.恒易融"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-139-2555ce3c4480>, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-139-2555ce3c4480>\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    pagetotal = results_page2.find('p', class_=\"page_all\").get_text()[3:-1]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "###full dataset including all investors. Tooo huge, more than 100000\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "           #'Referer': 'https://www.hengyirong.com/investment/history.html'}\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "urlprob = list()\n",
    "    \n",
    "for i in range(1):\n",
    "    response = ''\n",
    "    url = \"https://www.hengyirong.com/investment/history.html?page=%s\"%(i+1)\n",
    "    while response == '':\n",
    "        try:\n",
    "            \n",
    "            \n",
    "            response = requests.get(url,headers=headers)\n",
    "            results_page = BeautifulSoup(response.content,'lxml')  \n",
    "            \n",
    "            urlprime = list()\n",
    "            for t in results_page.find_all('a', class_='sy_liqi_caozuo'):\n",
    "                urlprime.append('https://www.hengyirong.com' + t.get('href'))\n",
    "            for url2 in urlprime:\n",
    "                \n",
    "                #headers2 = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "                 #         'Referer': url2,\n",
    "                   #       'Cookie': 'aliyungf_tc=AQAAAE9NhFc9ugQAgILennhmQEzeEMuP; PHPSESSID=ske5vokep7rsjfp56sai8m31m0',\n",
    "                    #       'Host' : 'www.hengyirong.com'}\n",
    "                response2 = requests.get(url2,headers=headers)\n",
    "                results_page2 = BeautifulSoup(response2.content,'lxml')\n",
    "                ##Date\n",
    "                date = results_page2.find('li', class_='sy_liqi_li1').get_text()[7:-3]\n",
    "                #title\n",
    "                title = results_page2.find('li', class_='sy_liqi_li1').get_text()[3:-3]\n",
    "                \n",
    "                try:\n",
    "            pagetotal = results_page2.find('p', class_=\"page_all\").get_text()[3:-1]\n",
    "            for pagenum in range(len(pagetotal)):\n",
    "                url3 = url2 + \"?page=%s\"%(pagenum +1)\n",
    "                    #headers3 = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "                     #     'Referer': url3,\n",
    "                      #    'Cookie': 'aliyungf_tc=AQAAAE9NhFc9ugQAgILennhmQEzeEMuP; PHPSESSID=ske5vokep7rsjfp56sai8m31m0',\n",
    "                       #    'Host' : 'www.hengyirong.com'}\n",
    "                    \n",
    "                    \n",
    "                response3 = requests.get(url3,headers=headers)\n",
    "                results_page3 = BeautifulSoup(response3.content,'lxml')\n",
    "                    \n",
    "            ##value\n",
    "                valueall = results_page3.find_all('span', class_='sy_liqi_jine')\n",
    "                for value in valueall:\n",
    "                    valuelist.append(value.get_text())\n",
    "            ##add date and title\n",
    "                    datelist.append(date)\n",
    "                    titlelist.append(title)\n",
    "                    \n",
    "            #maturity & rate\n",
    "                num = results_page3.find_all('span', class_='sy_liqi_num')\n",
    "                    \n",
    "                for j in range(len(num)):\n",
    "                    if j%2 == 0:\n",
    "                        maturlist.append(num[j].get_text())\n",
    "                    else:\n",
    "                        ratelist.append(num[j].get_text())\n",
    "        except:\n",
    "            ##value\n",
    "            valueall = results_page2.find_all('span', class_='sy_liqi_jine')\n",
    "            for value in valueall:\n",
    "                valuelist.append(value.get_text())\n",
    "                datelist.append(date)\n",
    "                titlelist.append(title) \n",
    "            \n",
    "            num = results_page2.find_all('span', class_='sy_liqi_num')\n",
    "                    \n",
    "            for j in range(len(num)):\n",
    "                if j%2 == 0:\n",
    "                    maturlist.append(num[j].get_text())\n",
    "                else:\n",
    "                    ratelist.append(num[j].get_text())\n",
    "                \n",
    "                \n",
    "                \n",
    "        except:\n",
    "            print(url)\n",
    "            urlprob.append(url)\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_all = results_page.find_all('td', class_='sy_liqi_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datelist = list()\n",
    "titlelist=list()\n",
    "for date in  date_all:\n",
    "    datelist.append(date.get_text()[4:-3])\n",
    "    titlelist.append(date.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.hengyirong.com/investment/historyDetail/id/6176.html\n"
     ]
    }
   ],
   "source": [
    "##a compromise way\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "           #'Referer': 'https://www.hengyirong.com/investment/history.html'}\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "urlprob = list()\n",
    "    \n",
    "for i in range(3):\n",
    "    response = ''\n",
    "    url = \"https://www.hengyirong.com/investment/history.html?page=%s\"%(i+1)\n",
    "    while response == '':\n",
    "        try:\n",
    "            \n",
    "            \n",
    "            response = requests.get(url,headers=headers)\n",
    "            results_page = BeautifulSoup(response.content,'lxml')  \n",
    "            \n",
    "            \n",
    "        ##value\n",
    "            valueall = results_page.find_all('span', class_='sy_liqi_jine')\n",
    "            for value in valueall:\n",
    "                valuelist.append(value.get_text())\n",
    "        ##Date AND #title\n",
    "            date_all = results_page.find_all('td', class_='sy_liqi_time')\n",
    "            \n",
    "            for date in date_all:\n",
    "                datelist.append(date.get_text()[4:-3])\n",
    "                titlelist.append(date.get_text())\n",
    "        \n",
    "            \n",
    "            urlprime = list()\n",
    "            for t in results_page.find_all('a', class_='sy_liqi_caozuo'):\n",
    "                urlprime.append('https://www.hengyirong.com' + t.get('href'))\n",
    "            for url2 in urlprime:\n",
    "                \n",
    "                #headers2 = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "                 #         'Referer': url2,\n",
    "                   #       'Cookie': 'aliyungf_tc=AQAAAE9NhFc9ugQAgILennhmQEzeEMuP; PHPSESSID=ske5vokep7rsjfp56sai8m31m0',\n",
    "                    #       'Host' : 'www.hengyirong.com'}\n",
    "                try:\n",
    "                    response2 = requests.get(url2,headers=headers)\n",
    "                    results_page2 = BeautifulSoup(response2.content,'lxml')\n",
    "            ##maturity    \n",
    "                    maturity = results_page2.find_all('span', class_='sy_liqi_num')[0].get_text()\n",
    "                    maturlist.append(maturity)\n",
    "            ##rate\n",
    "                    rate = results_page2.find_all('span', class_='sy_liqi_num')[1].get_text()\n",
    "                    ratelist.append(rate)\n",
    "                except:\n",
    "                    maturlist.append('check later')\n",
    "                    ratelist.append('check later')\n",
    "                    print(url2)\n",
    "                \n",
    "                \n",
    "                \n",
    "        except:\n",
    "            print(url)\n",
    "            urlprob.append(url)\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##a compromise way\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36'}\n",
    "           #'Referer': 'https://www.hengyirong.com/investment/history.html'}\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "urlprob = list()\n",
    "    \n",
    "for i in range(2):\n",
    "    response = ''\n",
    "    url = \"https://www.hengyirong.com/investment/history.html?page=%s\"%(i+1)\n",
    "\n",
    "            \n",
    "            \n",
    "    response = requests.get(url,headers=headers)\n",
    "    results_page = BeautifulSoup(response.content,'lxml')  \n",
    "            \n",
    "            \n",
    "        ##value\n",
    "    valueall = results_page.find_all('span', class_='sy_liqi_jine')\n",
    "    for value in valueall:\n",
    "        valuelist.append(value.get_text())\n",
    "        ##Date AND #title\n",
    "    date_all = results_page.find_all('td', class_='sy_liqi_time')\n",
    "            \n",
    "    for date in date_all:\n",
    "        datelist.append(date.get_text()[4:-3])\n",
    "        titlelist.append(date.get_text())\n",
    "        \n",
    "            \n",
    "    urlprime = list()\n",
    "    for t in results_page.find_all('a', class_='sy_liqi_caozuo'):\n",
    "        urlprime.append('https://www.hengyirong.com' + t.get('href'))\n",
    "    for url2 in urlprime:\n",
    "                \n",
    "                #headers2 = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "                 #         'Referer': url2,\n",
    "                   #       'Cookie': 'aliyungf_tc=AQAAAE9NhFc9ugQAgILennhmQEzeEMuP; PHPSESSID=ske5vokep7rsjfp56sai8m31m0',\n",
    "                    #       'Host' : 'www.hengyirong.com'}\n",
    "        response2 = requests.get(url2,headers=headers)\n",
    "        results_page2 = BeautifulSoup(response2.content,'lxml')\n",
    "            ##maturity    \n",
    "        \n",
    "        maturity = results_page2.find_all('span', class_='sy_liqi_num')[0].get_text()\n",
    "        maturlist.append(maturity)\n",
    "            ##rate\n",
    "        rate = results_page2.find_all('span', class_='sy_liqi_num')[1].get_text()\n",
    "        ratelist.append(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoin(a):\n",
    "   # a = list(a)\n",
    "    a = [x for x in a if x != ',']\n",
    "\n",
    "    magic = lambda nums: float(''.join(str(i) for i in nums))\n",
    "    a = magic(a)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "value2list=list()\n",
    "for v in valuelist:\n",
    "    value2list.append(stoin(v))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist.append((datelist[i], value2list[i], titlelist[i],ratelist[i], maturlist[i]))  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "outfile = open(\"hengyirong______plus.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Date, value(Yuan), title, Rate, Maturity(Month)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawlist2=list()\n",
    "for i in range(len(maturlist)):\n",
    "    rawlist2.append((ratelist[i], maturlist[i]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "outfile = open(\"hengyirong2.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Rate, Maturity(Month)\\n\")\n",
    "\n",
    "for r in rawlist2:\n",
    "    outfile.write(\"%s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  （4）. 信用宝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "uselist=list()\n",
    "\n",
    "urlprob = list()\n",
    "    \n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36',\n",
    "          'Refer': 'https://www.xyb100.com/invest/xtb',\n",
    "          'Origin': 'https://www.xyb100.com',\n",
    "          'X-Requested-With': 'XMLHttpRequest'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,1):\n",
    "    response = ''\n",
    "    url = \"https://www.xyb100.com/invest/xtb/xtb-data\"\n",
    "    form_data = {'pageNo': i}\n",
    "\n",
    "    while response == '':\n",
    "        try: \n",
    "            response = requests.post(url,headers=headers, data=form_data)\n",
    "            results_page = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "            num = results_page.find_all('td', class_=\"ui-size14\")\n",
    "            for j in range(len(num)):\n",
    "                if j%2 == 0:\n",
    "            ##rate\n",
    "                    ratelist.append(num[j].get_text()[:-1])\n",
    "                else:\n",
    "            ##maturity\n",
    "                    maturlist.append(num[j].get_text()[:-2])\n",
    "            ##Title\n",
    "            for title in results_page.find_all('td', class_=\"invest-title\"):\n",
    "                titlelist.append(title.find('a').get('title'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            urlprime = list()\n",
    "            for t in results_page.find_all('td', class_=\"invest-title\"):\n",
    "                url2 = t.find('a').get('href')\n",
    "                urlprime.append('https://www.xyb100.com' + url2)\n",
    "        \n",
    "            for url3 in urlprime:\n",
    "                response2 = requests.get(url3,headers=headers)\n",
    "                results_page2 = BeautifulSoup(response2.content,'lxml')\n",
    "        ##value\n",
    "                value = results_page2.find_all('p', class_=\"text\")[0].find('span', class_=\"span\").get_text()\n",
    "                valuelist.append(value)\n",
    "            \n",
    "        ##Date\n",
    "                date = results_page2.find('p', class_=\"text uimb10\").get_text()\n",
    "                datelist.append(date)\n",
    "            \n",
    "        ##Use\n",
    "                use = results_page2.find_all('li', class_=\"item\")[9].find('span', class_=\"span\").get_text()\n",
    "                uselist.append(use)\n",
    "            \n",
    "        \n",
    "        \n",
    "        except:\n",
    "            print(i)\n",
    "            #urlprob.append(urlprime)\n",
    "            datelist.append('check then')\n",
    "            valuelist.append('check then')\n",
    "            uselist.append('check then')\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2list = list()\n",
    "for i in datelist:\n",
    "    j = i.replace(' ','')\n",
    "    date2list.append(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date3list = list()\n",
    "for i in date2list:\n",
    "    j = i.replace('\\r\\n', '')\n",
    "    date3list.append(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date4list = list()\n",
    "for i in date3list:\n",
    "    j = i.replace('融资方于', '')\n",
    "    date4list.append(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "date5list = list()\n",
    "for i in date4list:\n",
    "    j = i.replace('（融资方保证按照借款用途使用资金）。', '')[0:10]\n",
    "    date5list.append(j)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoin(a):\n",
    "   # a = list(a)\n",
    "    a = [x for x in a if x != ',']\n",
    "\n",
    "    magic = lambda nums: float(''.join(str(i) for i in nums))\n",
    "    a = magic(a)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "value2list=list()\n",
    "for v in valuelist:\n",
    "    try:\n",
    "        value2list.append(stoin(v))\n",
    "    except:\n",
    "        value2list.append(v)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlist1=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist1.append((date5list[i], value2list[i], titlelist[i], uselist[i], ratelist[i], maturlist[i]))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "outfile = open(\"xinyongbao1_____plus.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Date, Value(Yuan), title, Use, Rate, Maturity(Month)\\n\")\n",
    "\n",
    "for r in rawlist1:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Date, Value(Yuan), Rate(%), Title, Use, Maturity(month)\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawlist2=list()\n",
    "for i in range(len(ratelist)):\n",
    "    rawlist2.append((ratelist[i], titlelist[i],  maturlist[i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "outfile = open(\"xinyongbao2.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Rate(%), Title,  Maturity(Month)\\n\")\n",
    "\n",
    "for r in rawlist2:\n",
    "    outfile.write(\"%s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5).融金宝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request URL: http://www.rjb777.com/WebService/Loan.svc/GetPageLoanList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Requests header\n",
    "Accept: application/json, text/javascript, */*; q=0.01\n",
    "Accept-Encoding: gzip, deflate\n",
    "Accept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7\n",
    "Connection: keep-alive\n",
    "Content-Length: 108\n",
    "Content-Type: application/json; charset=UTF-8\n",
    "Cookie: SECheck=3f66f101d64185f2e3bddb6440601e2ca544d9da; __jsluid=79ecc0142cc87baed589ade61ee4f50a; CNZZDATA1254790094=1813591682-1522281420-http%253A%252F%252Fwww.rjb777.com%252F%7C1522281420; UM_distinctid=1626f23fd5ebb-05212538448042-33697b07-13c680-1626f23fd5f3e2; ASP.NET_SessionId=5ovk41xuum3zhnc5kp3gw0dp; SRV=b0937cd0ac78e79805; CNZZDATA1271152961=517337351-1522277908-null%7C1522283391\n",
    "Host: www.rjb777.com\n",
    "Origin: http://www.rjb777.com\n",
    "Referer: http://www.rjb777.com/p2p/TendersLoanMore.aspx\n",
    "User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36\n",
    "X-Requested-With: XMLHttpRequest\n",
    "\n",
    "#Request Payload\n",
    "\n",
    "{\"currentPage\":2,\"pageSize\":10,\"filter\":\" \",\"orderBy\":\" ExamStatus ASC,BiddingProcess DESC,LoanNumber DESC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36',\n",
    "           #'Refer': 'http://www.rjb777.com/p2p/TendersLoanMore.aspx',\n",
    "           'Origin': 'http://www.rjb777.com',\n",
    "           'Host': 'www.rjb777.com',\n",
    "           'X-Requested-With': 'XMLHttpRequest',\n",
    "           'Cookie': 'username=kobe; __jsluid=79ecc0142cc87baed589ade61ee4f50a; UM_distinctid=1626f23fd5ebb-05212538448042-33697b07-13c680-1626f23fd5f3e2; ASP.NET_SessionId=5ovk41xuum3zhnc5kp3gw0dp; SRV=b0937cd0ac78e79805; SECheck=a1eec27c8db7d7cb51caf48ed4c5fa2bfc7f1b28; CNZZDATA1254790094=1813591682-1522281420-http%253A%252F%252Fwww.rjb777.com%252F%7C1522292237; CNZZDATA1271152961=517337351-1522277908-null%7C1522291405'}\n",
    "url = \"http://www.rjb777.com/p2p/TendersLoanMore.aspx\"\n",
    "payload = {\"currentPage\": 4,\n",
    "            \"pageSize\": 10,\n",
    "            \"filter\": \" \",\n",
    "            \"orderBy\": 'ExamStatus ASC,BiddingProcess DESC,LoanNumber DESC'}\n",
    "session = requests.Session()\n",
    "response = session.get(url,data=payload, headers=headers)\n",
    "#results_page = BeautifulSoup(response.text, 'html.parser')\n",
    "results_page = BeautifulSoup(response.content,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##rest is not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6)融金所"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://www.rjs.com/invest/rplanlist2017/p/2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.融金计划\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "          'Server': 'wswaf/1.15.2-1.el6'}\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "urlprob = list()\n",
    "    \n",
    "for i in range(3):\n",
    "    response = ''\n",
    "    url = \"https://www.rjs.com/invest/rplanlist2017/p/%s.html\"%(i+1)\n",
    "    while response == '':\n",
    "        try:\n",
    "             \n",
    "            response = requests.post(url,headers=headers)\n",
    "            results_page = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "        ##Title\n",
    "            for title in results_page.find_all('p', class_=\"tit\"):\n",
    "                titlelist.append(title.get_text())\n",
    "        ##Rate\n",
    "            for rate in results_page.find_all('dl', class_=\"rate\"):\n",
    "                ratelist.append(rate.find('dt').get_text())\n",
    "        ##maturity\n",
    "\n",
    "            for matur in results_page.find_all('dl', class_=\"date\"):\n",
    "                maturlist.append(matur.find('dt').get_text()[:-1])\n",
    "        #value(万元！！！！！！！！！！)\n",
    "            for value in results_page.find_all('dl', class_=\"money\"):\n",
    "                valuelist.append(value.find('dt').get_text()[:-2])\n",
    "        \n",
    "        \n",
    "            \n",
    "            urlprime = list()\n",
    "            for t in results_page.find_all('div', class_=\"tit_w\"):\n",
    "                urlprime.append('https://www.rjs.com' + t.find('a').get('href'))\n",
    "            for url2 in urlprime:\n",
    "                response2 = requests.post(url2,headers=headers)\n",
    "                results_page2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "            ##date   \n",
    "                datelist.append(results_page2.find_all('li', class_=\"left_bottom\")[2].find('span').get_text()[:10])\n",
    "                \n",
    "                \n",
    "        except:\n",
    "            print(url)\n",
    "            urlprob.append(url)\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist.append((datelist[i], valuelist[i], ratelist[i], titlelist[i], maturlist[i]))\n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "outfile = open(\"rjs融金计划________plus.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Date, Value(万元), Rate(%), Title, Maturity(month)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.月月升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "          'Server': 'wswaf/1.15.2-1.el6'}\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "urlprob = list()\n",
    "    \n",
    "for i in range(3):\n",
    "    response = ''\n",
    "    url = \"https://www.rjs.com/invest/rjsmonthlist/p/%s.html\"%(i+1)\n",
    "    while response == '':\n",
    "        try:\n",
    "             \n",
    "            response = requests.post(url,headers=headers)\n",
    "            results_page = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "        ##Title\n",
    "            for title in results_page.find_all('p', class_=\"tit\"):\n",
    "                titlelist.append(title.get_text())\n",
    "        ##Rate\n",
    "            for rate in results_page.find_all('dl', class_=\"rate\"):\n",
    "                ratelist.append(rate.find('dt').get_text())\n",
    "        ##maturity\n",
    "\n",
    "            for matur in results_page.find_all('dl', class_=\"date\"):\n",
    "                maturlist.append(matur.find('dt').get_text()[:-1])\n",
    "        #value(万元！！！！！！！！！！)\n",
    "            for value in results_page.find_all('dl', class_=\"money\"):\n",
    "                valuelist.append(value.find('dt').get_text()[:-2])\n",
    "        \n",
    "        \n",
    "            \n",
    "            urlprime = list()\n",
    "            for t in results_page.find_all('div', class_=\"tit_w\"):\n",
    "                urlprime.append('https://www.rjs.com' + t.find('a').get('href'))\n",
    "            for url2 in urlprime:\n",
    "                response2 = requests.post(url2,headers=headers)\n",
    "                results_page2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "            ##date   \n",
    "                datelist.append(results_page2.find_all('li', class_=\"left_bottom\")[2].find('span').get_text()[:10])\n",
    "                \n",
    "                \n",
    "        except:\n",
    "            print(url)\n",
    "            urlprob.append(url)\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist.append((datelist[i], valuelist[i], ratelist[i], titlelist[i], maturlist[i]))\n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "outfile = open(\"rj月月升____plus.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Date, Value(万元), Rate(%), Title, Maturity(month)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) 拓道金服"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoin(a):\n",
    "   # a = list(a)\n",
    "    a = [x for x in a if x != ',']\n",
    "\n",
    "    magic = lambda nums: float(''.join(str(i) for i in nums))\n",
    "    a = magic(a)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "          'X-Requested-With': 'XMLHttpRequest',\n",
    "          'Cookie': 'UM_distinctid=162749bdfe142b-02411d2a6b0f46-33697b07-13c680-162749bdfe3553; JSESSIONID=AE77A1872C0F03BC52932D940ACA51BC; CNZZDATA1256118936=221408494-1522369688-https%253A%252F%252Fwww.google.com%252F%7C1522380526',\n",
    "          'Host': 'www.51tuodao.com',\n",
    "          'Referer': 'https://www.51tuodao.com/front/invest/index'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "urlprob = list()\n",
    "\n",
    "\n",
    "for i in range(5):#9000\n",
    "    response = ''\n",
    "    #url = 'https://www.51tuodao.com/json/borrow/list2?t=1522352813382&page=%s&itemsPerPage=7&orderBy=addtime&order=desc'%(i+1)\n",
    "    url = 'https://www.51tuodao.com/json/borrow/list2?t=1522381604891&page=%s&itemsPerPage=7&orderBy=addtime&order=desc'%(i+1)\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.get(url,headers=headers)\n",
    "            results_page = BeautifulSoup(response.content,'lxml')\n",
    "    #Title\n",
    "            for title in results_page.find_all('p', class_='fl'):\n",
    "                titlelist.append(title.get_text())\n",
    "    ##maturity\n",
    "    ##rate\n",
    "    ##part value\n",
    "            valuerlist=list()\n",
    "            for t in results_page.find_all('div', class_='contents'):\n",
    "                ratelist.append(t.find_all('dd')[0].get_text()[1:-1])\n",
    "                maturlist.append(t.find_all('dd')[1].get_text()[1:-5])\n",
    "                valuerlist.append(t.find_all('dd')[2].get_text()[1:-6])\n",
    "    ##value string to float\n",
    "            valuer2list=list()\n",
    "            for v in valuerlist:\n",
    "                valuer2list.append(stoin(v))\n",
    "            urlprime = list()\n",
    "            for t in results_page.find_all('a', target='_blank'):\n",
    "                urlprime.append('https://www.51tuodao.com/json/uc/tenderList?t=Thu%20Mar%2029%202018%2023:34:44%20GMT-0400%20(EDT)&page=1&itemsPerPage=7&orderBy=id&order=desc&nid=' + t.get('id')[4:])\n",
    "  \n",
    "            for urlnum in range(len(urlprime)):\n",
    "                url_1 = urlprime[urlnum]\n",
    "        \n",
    "\n",
    "                response_1 = requests.get(url_1,headers=headers).json()\n",
    "                page_total = response_1['paginator']['pages']\n",
    "        \n",
    "        ##Date\n",
    "                try:##if nobody invested yet\n",
    "                    datelist.append(response_1['dataRows'][0]['addtime'][:10])\n",
    "                except:\n",
    "                    datelist.append('Check by url')\n",
    "        ##value\n",
    "                #valueadd = valuer2list[urlnum]\n",
    "                for pagen in range(1,(page_total+1)):\n",
    "                    valueadd = valuer2list[urlnum]\n",
    "                    url_n = url_1[:125] + str(pagen) + url_1[126:]\n",
    "                    response_n = requests.get(url_n,headers=headers).json()\n",
    "                    try:\n",
    "                        for ninvestor in range(len(response_n['dataRows'])):\n",
    "                            valueadd += float(response_n['dataRows'][ninvestor]['account'])\n",
    "                            valuer2list[urlnum] = valueadd\n",
    "                    except:\n",
    "                        pass\n",
    "                valuelist.append(valueadd)\n",
    "                \n",
    "            \n",
    "    \n",
    "        except:\n",
    "            print(url)\n",
    "            urlprob.append(url)\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue    \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist.append((datelist[i], valuelist[i], ratelist[i], titlelist[i], maturlist[i]))\n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "outfile = open(\"tuodaojinfu.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Date, Value(万元), Rate(%), Title, Maturity(month)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8)理财范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.短期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "headers = {'User-Agent': 'User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36',\n",
    "          'Refer': 'http://www.licaifan.com',\n",
    "          'Origin': 'https://www.xyb100.com',\n",
    "          'X-Requested-With': 'XMLHttpRequest',\n",
    "          'Cookie': 'PHPSESSID=cedqqh71b1e3huks9hlbicb4q4; gr_user_id=9e328348-6978-40a2-b830-133b5ec9c092; Hm_lvt_6731266628b1cd5442c083d7f4d0bedb=1522384453,1522384553,1522384796; Hm_lpvt_6731266628b1cd5442c083d7f4d0bedb=1522385257; gr_session_id_b00958a1397e187c=42cd04e8-2d7b-493e-88bc-00d94b49955f'}\n",
    "url = \"http://www.licaifan.com/project/list\"\n",
    "form_data = {'page': '5',\n",
    "            'period_type': '1'}#3:short-term, #2: medium-termm, #3: long-term\n",
    "response = requests.post(url,headers=headers, data=form_data).json()\n",
    "#results_page = BeautifulSoup(response.text, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "headers = {'User-Agent': 'User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36',\n",
    "          'X-Requested-With': 'XMLHttpRequest'}\n",
    "\n",
    "url = \"http://www.licaifan.com/project/list\"\n",
    "form_data = {'page': '401',\n",
    "            'period_type': '2'}#3:short-term, #2: medium-termm, #3: long-term\n",
    "response = requests.post(url,headers=headers, data=form_data).json()\n",
    "#results_page = BeautifulSoup(response.text, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value\n",
    "#rate\n",
    "#urlprime\n",
    "#maturity\n",
    "valuelist = list()\n",
    "ratelist = list()\n",
    "maturlist = list()\n",
    "urlprime = list()\n",
    "for content in response['project']:\n",
    "    valuelist.append(content['amount'])\n",
    "    ratelist.append(content['apr'])\n",
    "    maturlist.append(content['period'])\n",
    "    urlprime.append('http://www.licaifan.com' + content['name'][9: content['name'].find('>')-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url2 = urlprime[2]\n",
    "response2 = requests.get(url2,headers=headers)\n",
    "results_page2 = BeautifulSoup(response2.text,'html.parser')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'消费金融-2017-KZ0061247- 约定年化借款利率10.5% - 期限5个月 - 理财范'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Title\n",
    "\n",
    "results_page2.find('title').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-12-27'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Due date\n",
    "results_page2.find_all('span', class_=\"option\")[1].find('span').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.中期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medium-term\n",
    "import time\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36',\n",
    "          'X-Requested-With': 'XMLHttpRequest'}\n",
    "\n",
    "\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "urlprob = list()\n",
    "    \n",
    "for i in range(200,202):#2: 550\n",
    "    response = ''\n",
    "    url = \"http://www.licaifan.com/project/list\"\n",
    "    form_data = {'page': str(i+1),\n",
    "                'period_type': '2'}#3:short-term, #2: medium-termm, #3: long-term\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.post(url,headers=headers, data=form_data).json()\n",
    "            #results_page = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "\n",
    "            urlprime = list()\n",
    "            for content in response['project']:\n",
    "            #value\n",
    "                valuelist.append(content['amount'])\n",
    "            #rate\n",
    "                ratelist.append(content['apr'])\n",
    "            #maturity\n",
    "                maturlist.append(content['period'])\n",
    "            #urlprime\n",
    "                urlprime.append('http://www.licaifan.com' + content['name'][9: content['name'].find('>')-1])\n",
    "        \n",
    "        \n",
    "            for url2 in urlprime:\n",
    "                try:\n",
    "                    response2 = requests.get(url2,headers=headers)\n",
    "                    results_page2 = BeautifulSoup(response2.text,'html.parser')\n",
    "            ##Due date\n",
    "                    datelist.append(results_page2.find_all('span', class_=\"option\")[1].find('span').get_text())\n",
    "            #Title\n",
    "\n",
    "                    titlelist.append(results_page2.find('title').get_text())\n",
    "                except:\n",
    "                    datelist.append('check later')\n",
    "                    titlelist.append('check later')\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "        except:\n",
    "            print(form_data)\n",
    "            #urlprob.append(url)\n",
    "            #datelist.append('check later')\n",
    "            #titlelist.append('check later')\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matur2list = list()\n",
    "for mat in maturlist:\n",
    "    matur2list.append(mat[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##value string to float\n",
    "valuer2list = list()\n",
    "for v in valuerlist:\n",
    "    valuer2list.append(stoin(v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist.append((datelist[i], value2list[i], ratelist[i], titlelist[i], matur2list[i]))\n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "outfile = open(\"licaifan_2.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Due Date, Value(万元), Rate(%), Title, Maturity(day)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.长期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.licaifan.com/loan/detail/a8aece0882371f438c829bccb995a927\n",
      "http://www.licaifan.com/loan/detail/6f20b6878aa610b128facd8aeb745c8b\n",
      "http://www.licaifan.com/loan/detail/2300b63af8665d2c9b6944135776f084\n",
      "http://www.licaifan.com/loan/detail/3efe6c32370fb3b8bcba9451df36483a\n",
      "http://www.licaifan.com/loan/detail/3041372c228449ada7c295d940697a3a\n",
      "http://www.licaifan.com/loan/detail/baa0cb562de48fbabbd65b0f85243dc2\n",
      "http://www.licaifan.com/loan/detail/9bd96e176bbedf4d017f4b438bd613e3\n",
      "http://www.licaifan.com/loan/detail/8eeedc66ea8fbcdf2e74294037c2f389\n",
      "http://www.licaifan.com/loan/detail/d0310f4638328873adcc399bca91eb4e\n",
      "http://www.licaifan.com/loan/detail/a415f28ee13ec97d6219867fbc7bbadb\n",
      "http://www.licaifan.com/loan/detail/31df640a39af675eae099e0d9ace7ea1\n",
      "http://www.licaifan.com/loan/detail/cd9840da1d1e99d7a4455acf36785fc6\n",
      "http://www.licaifan.com/loan/detail/e5060c47839ae5b62a327be0310f7981\n",
      "http://www.licaifan.com/loan/detail/f31c62b1be87ee00a16b9e51482263a7\n",
      "http://www.licaifan.com/loan/detail/1f75943068ed444fb245bf2a6a291c0c\n",
      "http://www.licaifan.com/loan/detail/736d0469753aa6d375ef9679ef3465fb\n",
      "http://www.licaifan.com/loan/detail/ebb2f6ac7f9ba659ac28c0b0433c7ce1\n",
      "http://www.licaifan.com/loan/detail/5a78f1d526e0a3c8b4f759968b660b8c\n",
      "http://www.licaifan.com/loan/detail/3d5ac5d089b2a3265e292f374567eacf\n",
      "http://www.licaifan.com/loan/detail/94944b200934137ce827029c962b3e0f\n",
      "http://www.licaifan.com/loan/detail/7d757465b17e6b28ef00f9f1551d5689\n",
      "http://www.licaifan.com/loan/detail/5053f99d12400ffb9eebe6992bf56e82\n",
      "http://www.licaifan.com/loan/detail/6c5eb9a660d5b3ae277726c6ec098192\n",
      "http://www.licaifan.com/loan/detail/e7cdd6455edf5fe52b5f5d23971f49c0\n",
      "http://www.licaifan.com/loan/detail/f9d8a11e28de83af2f210a46dd624a64\n",
      "http://www.licaifan.com/loan/detail/194a988102edcd4b67accb0110e20fd3\n",
      "http://www.licaifan.com/loan/detail/cdfc98d231a27426af33906c0a12d319\n",
      "http://www.licaifan.com/loan/detail/03d8a1edcf4501ab378313b04c24afa2\n",
      "http://www.licaifan.com/loan/detail/8b6041792aeeeef69b5ba034cb7577b7\n",
      "http://www.licaifan.com/loan/detail/72af543e6d0f8714d3185516e3afe9f4\n",
      "http://www.licaifan.com/loan/detail/b38801baf56109a4576501d6c6ec3a81\n",
      "http://www.licaifan.com/loan/detail/a9eff89daa0dd80a9af1fc1bed016a9f\n",
      "http://www.licaifan.com/loan/detail/6746201227327c1c921895265c1c58d2\n",
      "http://www.licaifan.com/loan/detail/51c66183db882de9d51dac0dabec5323\n",
      "http://www.licaifan.com/loan/detail/0174a6d48b2b6c3d8c1928c759583f40\n",
      "http://www.licaifan.com/loan/detail/7c39352813045206add05c79f8662e1c\n",
      "http://www.licaifan.com/loan/detail/1d4b76905ac6652ff780a48096f49879\n",
      "http://www.licaifan.com/loan/detail/fe22fd595b5383f9ce1f7e2abd10584f\n",
      "http://www.licaifan.com/loan/detail/8d462d62ac0734241b98c97bafca11fc\n",
      "http://www.licaifan.com/loan/detail/5c6c364bf5f3e00a2e2b017859dde995\n",
      "http://www.licaifan.com/loan/detail/fc0aafd651946d038137a3b480c2e639\n",
      "http://www.licaifan.com/loan/detail/d466c07ceb8f2e0704c4da35f9bd11c9\n",
      "http://www.licaifan.com/loan/detail/57902633a9b75c60dd351cd33856950b\n",
      "http://www.licaifan.com/loan/detail/fbd7ac6e006db321fd81a10586907434\n",
      "http://www.licaifan.com/loan/detail/ff41e552dba792c96fcafeb701076aed\n",
      "http://www.licaifan.com/loan/detail/77b1932b3eec9f094a2b103001f0dff1\n",
      "http://www.licaifan.com/loan/detail/a4ddab7e3c43d76cfff0dc4189a5df2a\n",
      "http://www.licaifan.com/loan/detail/25c483880f8520828af4dba5d726d1e7\n",
      "http://www.licaifan.com/loan/detail/6721e8332154c61a68a38816866a869f\n",
      "http://www.licaifan.com/loan/detail/caec785d9e8e4f690ce7d9a4d37cb677\n",
      "http://www.licaifan.com/loan/detail/87f8e1e0156138cca3206c48b7098f41\n",
      "http://www.licaifan.com/loan/detail/ad087ba3e8f8063d81a2ae71e365a81c\n",
      "http://www.licaifan.com/loan/detail/0ac04853f8058f61af1ca7630e786d22\n",
      "http://www.licaifan.com/loan/detail/7c0ffb7232b77166913c3e8dec47ad07\n",
      "http://www.licaifan.com/loan/detail/9dc5e69cae378ee05057e4489ad8b728\n",
      "http://www.licaifan.com/loan/detail/715f390c232030c410b5ff0aa1034a1c\n",
      "http://www.licaifan.com/loan/detail/08a060a61b90a099b277ce6a1982dfbb\n",
      "http://www.licaifan.com/loan/detail/47d288215c79c95a062b84eb57b96058\n",
      "http://www.licaifan.com/loan/detail/fe7f7a0a7e51ef3f523048e2ac5e24c7\n",
      "http://www.licaifan.com/loan/detail/08a83ab0d6cfa10c7dc6844badeeb9de\n",
      "http://www.licaifan.com/loan/detail/e855978554e4c9899c4a2953e7f73013\n",
      "http://www.licaifan.com/loan/detail/7f7fc17485016b50781712c529de1df4\n",
      "http://www.licaifan.com/loan/detail/de4d4ada2968c13a4eb3d7f023fd42a6\n",
      "http://www.licaifan.com/loan/detail/88839a645726325fcbd8419f5fb05d45\n",
      "http://www.licaifan.com/loan/detail/b5a043534c00c86a0c8487b42d4b3e29\n",
      "http://www.licaifan.com/loan/detail/db5868f688fa2aedf45453ed89299e8a\n",
      "http://www.licaifan.com/loan/detail/ed8f5668d1b31eb658208a6c8ffdd233\n",
      "http://www.licaifan.com/loan/detail/95a1c096512dbb572d74f4fcbf6bfbfb\n",
      "http://www.licaifan.com/loan/detail/0c4d2507437b59833b44f6367c6222c0\n",
      "http://www.licaifan.com/loan/detail/4a33edb840d8caeb24bbcb1b0ce1d8d7\n",
      "http://www.licaifan.com/loan/detail/896f3d760a0422dbd7854e99f6224763\n",
      "http://www.licaifan.com/loan/detail/b817f8dad313f809b7e71a53e14a9231\n",
      "http://www.licaifan.com/loan/detail/361f984ff0040fbc17be3547788ad9f3\n",
      "http://www.licaifan.com/loan/detail/517f62b2ea7e49d5faf86c104dba801f\n",
      "http://www.licaifan.com/loan/detail/88e55a033cf994dc7a12e1cd3bd94148\n",
      "http://www.licaifan.com/loan/detail/53a321a3dd5fec15174c52abc7dca46a\n",
      "{'page': '658', 'period_type': '1'}\n",
      "Connection refused by the server..\n",
      "Let me sleep for 5 seconds\n",
      "ZZzzzz...\n",
      "Was a nice sleep, now let me continue...\n",
      "http://www.licaifan.com/loan/detail/e271b6eda6d30235aaec1743673316ce\n",
      "http://www.licaifan.com/loan/detail/9b7edc4dfd8e15db7b795826ad0a967b\n",
      "http://www.licaifan.com/loan/detail/60e6ecda2f69cba0035c7d675fdd9c7c\n",
      "http://www.licaifan.com/loan/detail/5eb1147cf31f1efda0047bcbfbe67783\n",
      "http://www.licaifan.com/loan/detail/29eb72af70b45ea8994b6d0256b1b97f\n",
      "http://www.licaifan.com/loan/detail/5c43b9568403ee749d068633ddb3535c\n",
      "http://www.licaifan.com/loan/detail/2e9cf17676a160fc8e5000d4bf513e1b\n",
      "http://www.licaifan.com/loan/detail/4218470a524ef1991202bb63abee5d72\n",
      "http://www.licaifan.com/loan/detail/a4396f61160d9bfa1ea9114dacd37247\n",
      "http://www.licaifan.com/loan/detail/a666b5dec0048c93e4e6cf6fda6e09bd\n",
      "http://www.licaifan.com/loan/detail/f633469121cb1895ba8023439e8197df\n",
      "http://www.licaifan.com/loan/detail/c654fadc9a9b502997ce42c9dc82ece2\n",
      "http://www.licaifan.com/loan/detail/3f54346a0ad0508b8829bbecff61f297\n",
      "http://www.licaifan.com/loan/detail/002f9c8cee878b64a747a2c211da7d83\n",
      "http://www.licaifan.com/loan/detail/d72eecc6b164864790fe25f2bd64a8ab\n",
      "http://www.licaifan.com/loan/detail/4fe560444cca7edf1c75e4fa492ff7d2\n",
      "http://www.licaifan.com/loan/detail/020f6fecd026539260779d34aa1a6944\n",
      "{'page': '768', 'period_type': '1'}\n",
      "Connection refused by the server..\n",
      "Let me sleep for 5 seconds\n",
      "ZZzzzz...\n",
      "Was a nice sleep, now let me continue...\n",
      "http://www.licaifan.com/loan/detail/06b44f22bf01b4bad31391ffe00009c4\n",
      "http://www.licaifan.com/loan/detail/4ea01965a7b1b4359cdabed6e3e6936b\n",
      "http://www.licaifan.com/loan/detail/527c815c48b61dcafe755b5d425115ec\n",
      "http://www.licaifan.com/loan/detail/a372457bfef3916c4b3dbcdcb7939784\n",
      "http://www.licaifan.com/loan/detail/400362daca8ad3cbfaf07300bc4bd898\n",
      "http://www.licaifan.com/loan/detail/e8630344970962450dbedfcd4cc6d718\n",
      "http://www.licaifan.com/loan/detail/2080dd731c0a27c6944f58acae270b81\n",
      "http://www.licaifan.com/loan/detail/ada9e980b20ac07f6a938ef15106c224\n",
      "http://www.licaifan.com/loan/detail/a97484e07cad027a9fb828764c1dcf6a\n",
      "http://www.licaifan.com/loan/detail/090afe0d4abb5dfdccb84641fe115680\n",
      "http://www.licaifan.com/loan/detail/885ca3d99fd35f509a2aa0130e8bf64f\n",
      "{'page': '996', 'period_type': '1'}\n",
      "Connection refused by the server..\n",
      "Let me sleep for 5 seconds\n",
      "ZZzzzz...\n",
      "Was a nice sleep, now let me continue...\n",
      "{'page': '1005', 'period_type': '1'}\n",
      "Connection refused by the server..\n",
      "Let me sleep for 5 seconds\n",
      "ZZzzzz...\n",
      "Was a nice sleep, now let me continue...\n",
      "http://www.licaifan.com/loan/detail/254b6cccc84a3b7e5c696e67c9ef656e\n",
      "http://www.licaifan.com/loan/detail/9e411b2d0cbcc1d9cd8775e89e96774f\n",
      "http://www.licaifan.com/loan/detail/3ea816621e0d8ecd5e534ec28051d4d5\n",
      "http://www.licaifan.com/loan/detail/0a6fbee9b5f6092233b7921f39554a33\n",
      "http://www.licaifan.com/loan/detail/2b6bb5354a56ce256116b6b307a1ea10\n",
      "http://www.licaifan.com/loan/detail/db00f1b7fdf48fd26b5fb5f309e9afaf\n",
      "http://www.licaifan.com/loan/detail/c370416bd42d48c75ceeba04434460f2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.licaifan.com/loan/detail/52d083725702045a8fa133362bc66318\n",
      "http://www.licaifan.com/loan/detail/177da57035b03c2eb2cbe9b872348d15\n",
      "http://www.licaifan.com/loan/detail/f30824bacaaabc2fc3aa0b6d658a56e9\n",
      "http://www.licaifan.com/loan/detail/70d85f35a1fdc0ab701ff78779306407\n",
      "http://www.licaifan.com/loan/detail/927b028cfa24b23a09ff20c1a7f9b398\n",
      "http://www.licaifan.com/loan/detail/89562dccfeb1d0394b9ae7e09544dc70\n",
      "http://www.licaifan.com/loan/detail/8b519f198dd26772e3e82874826b04aa\n",
      "http://www.licaifan.com/loan/detail/1eb590c1259ff05809830227e2b7e782\n",
      "http://www.licaifan.com/loan/detail/32b127307a606effdcc8e51f60a45922\n",
      "http://www.licaifan.com/loan/detail/082a8bbf2c357c09f26675f9cf5bcba3\n",
      "http://www.licaifan.com/loan/detail/c7be03f5d811ed29c328526ca8ab0d61\n",
      "http://www.licaifan.com/project/detail/45f31d16b1058d586fc3be7207b58053\n",
      "http://www.licaifan.com/project/detail/333ac5d90817d69113471fbb6e531bee\n",
      "http://www.licaifan.com/project/detail/a012869311d64a44b5a0d567cd20de04\n",
      "http://www.licaifan.com/project/detail/07a4e20a7bbeeb7a736682b26b16ebe8\n",
      "http://www.licaifan.com/project/detail/a0872cc5b5ca4cc25076f3d868e1bdf8\n",
      "http://www.licaifan.com/lease/detail/d5cfead94f5350c12c322b5b664544c1\n",
      "http://www.licaifan.com/lease/detail/65658fde58ab3c2b6e5132a39fae7cb9\n",
      "http://www.licaifan.com/lease/detail/b5b41fac0361d157d9673ecb926af5ae\n",
      "http://www.licaifan.com/project/detail/c8fbbc86abe8bd6a5eb6a3b4d0411301\n"
     ]
    }
   ],
   "source": [
    "#long-term\n",
    "import time\n",
    "\n",
    "\n",
    "import datetime\n",
    "import requests, json, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36',\n",
    "          'X-Requested-With': 'XMLHttpRequest'}\n",
    "\n",
    "\n",
    "titlelist=list()\n",
    "ratelist=list()\n",
    "valuelist=list()\n",
    "maturlist=list()\n",
    "datelist=list()\n",
    "\n",
    "urlprob = list()\n",
    "    \n",
    "for i in range(1500):#1:1500,   2: 550,   3: 600\n",
    "    response = ''\n",
    "    url = \"http://www.licaifan.com/project/list\"\n",
    "    form_data = {'page': str(i+1),\n",
    "                'period_type': '1'}#3:short-term, #2: medium-termm, #3: long-term\n",
    "    while response == '':\n",
    "        try:\n",
    "            response = requests.post(url,headers=headers, data=form_data).json()\n",
    "            #results_page = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "\n",
    "            urlprime = list()\n",
    "            for content in response['project']:\n",
    "            #value\n",
    "                valuelist.append(content['amount'])\n",
    "            #rate\n",
    "                ratelist.append(content['apr'])\n",
    "            #maturity\n",
    "                maturlist.append(content['period'])\n",
    "            #urlprime\n",
    "                urlprime.append('http://www.licaifan.com' + content['name'][9: content['name'].find('>')-1])\n",
    "        \n",
    "        \n",
    "            for url2 in urlprime:\n",
    "                try:\n",
    "                    response2 = requests.get(url2,headers=headers)\n",
    "                    results_page2 = BeautifulSoup(response2.text,'html.parser')\n",
    "            ##Due date\n",
    "                    datelist.append(results_page2.find_all('span', class_=\"option\")[1].find('span').get_text())\n",
    "            #Title\n",
    "\n",
    "                    titlelist.append(results_page2.find('title').get_text())\n",
    "                except:\n",
    "                    datelist.append('check later')\n",
    "                    titlelist.append('check later')\n",
    "                    urlprob.append(url2)\n",
    "                    print(url2)\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "        except:\n",
    "            print(form_data)\n",
    "            #urlprob.append(url)\n",
    "            #datelist.append('check later')\n",
    "            #titlelist.append('check later')\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##value string to float\n",
    "value2list = list()\n",
    "for v in valuelist:\n",
    "    value2list.append(stoin(v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matur2list = list()\n",
    "for mat in maturlist:\n",
    "    matur2list.append(mat[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlist=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist.append((datelist[i], value2list[i], ratelist[i], titlelist[i], matur2list[i]))\n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "outfile = open(\"licaifan_1.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Due Date, Value(万元), Rate(%), Title, Maturity(day)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.licaifan.com/loan/detail/f9d8a11e28de83af2f210a46dd624a64\n",
      "http://www.licaifan.com/loan/detail/2080dd731c0a27c6944f58acae270b81\n"
     ]
    }
   ],
   "source": [
    "add_datelist = list()\n",
    "add_titlelist = list()\n",
    "\n",
    "extraurlprob = list()\n",
    "\n",
    "for failurl in urlprob:\n",
    "    try:\n",
    "        response_add = requests.get(failurl,headers=headers)\n",
    "        results_page_add = BeautifulSoup(response_add.text,'html.parser')\n",
    "            ##Due date\n",
    "        add_datelist.append(results_page_add.find_all('span', class_=\"option\")[1].find('span').get_text())\n",
    "            #Title\n",
    "\n",
    "        add_titlelist.append(results_page_add.find('title').get_text())\n",
    "    except:\n",
    "        add_datelist.append('check later')\n",
    "        add_titlelist.append('check later')\n",
    "        extraurlprob.append(failurl)\n",
    "        print(failurl) \n",
    "\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2list = datelist\n",
    " \n",
    "\n",
    "for numd2 in range(len(add_datelist)):\n",
    "    for numd1 in range(len(date2list)):\n",
    "        if date2list[numd1] == 'check later':\n",
    "            date2list[numd1]= add_datelist[numd2]\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    continue\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "title2list = titlelist\n",
    "\n",
    "for numt2 in range(len(add_titlelist)):\n",
    "    for numt1 in range(len(title2list)):\n",
    "        if title2list[numt1] == 'check later':\n",
    "            title2list = add_datelist[numd2]\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlist3=list()\n",
    "for i in range(len(datelist)):\n",
    "    rawlist3.append((datelist[i], value2list[i], ratelist[i], titlelist[i], matur2list[i]))\n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "outfile = open(\"licaifan_1___1.csv\", \"w\", encoding='utf_8_sig')\n",
    "\n",
    "outfile.write(\"Due Date, Value(万元), Rate(%), Title, Maturity(day)\\n\")\n",
    "\n",
    "for r in rawlist:\n",
    "    outfile.write(\"%s, %s, %s, %s, %s\\n\" % r)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
